# ğŸ“¦ Delivery Market Analysis

![Python](https://img.shields.io/badge/Python-3.11+-blue.svg)
![DuckDB](https://img.shields.io/badge/DuckDB-enabled-yellow.svg)
![Streamlit](https://img.shields.io/badge/Streamlit-dashboard-red.svg)
![Plotly](https://img.shields.io/badge/Plotly-charts-orange.svg)
![RapidFuzz](https://img.shields.io/badge/RapidFuzz-matching-lightgrey.svg)
![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)

## ğŸ§  Short Intro

BeCode project (Data Science & AI Bootcamp).  
In 4 days I built an end-to-end delivery market analysis across three platforms, from raw SQLite databases to a DuckDB semantic layer and a Streamlit dashboard.

---

## ğŸš€ Highlights

- **End-to-end pipeline:** SQLite â†’ DuckDB (semantic layer) â†’ Streamlit dashboard  
- **SQL-heavy analysis** with clean, reusable views (`stg_*` and convenience views)  
- **Cross-platform entity resolution (G1)** to quantify overlap between platforms  
- **Geospatial insights:** coverage hotspots, dead zones proxy, dish availability maps  
- **Data quality handling:** invalid prices filtered, UberEats hours parsed from minutes since midnight  

---

## ğŸ“˜ BeCode Assignment

### ğŸ¯ Context

We analyze food delivery data to uncover actionable insights for restaurant partners and consumers.  
The goal is to explore trends, customer preferences, and market dynamics.

### âœ… Must-have business questions

- Price distribution of menu items  
- Distribution of restaurants per location  
- Top 10 pizza restaurants by rating  
- Map locations offering kapsalons (or another dish) and their average price  

### ğŸ’¡ Open-ended questions covered

- Best price-to-rating ratio (value proxy)  
- Delivery dead zones (low coverage proxy using geo and location aggregation)  
- Vegetarian and vegan availability by area (menu text heuristic)  
- **WHO (World Hummus Order):** top 3 hummus restaurants  
- Original questions (examples):  
  - Price outliers per platform (z-score)  
  - Chains vs independent proxy (repeated names across cities)  
  - Late-night availability on UberEats using hours data  

---

## ğŸ§‘â€ğŸ’» What I Learned / Personal Note

This was a 4-day BeCode project and I genuinely enjoyed it because it combines SQL and Python in one realistic workflow. I learned a lot about designing a semantic layer, dealing with messy source data, and turning an analysis into a small analytics product.

Instead of stopping at a notebook, I pushed it further by building an interactive Streamlit app to make the insights explorable and presentation-ready.

---

## ğŸ’¾ Data

- **Input format:** SQLite databases (not committed to Git)  
  - `deliveroo.db`  
  - `takeaway.db`  
  - `ubereats.db`  

---

## ğŸ›  Tech Stack

- Python, Pandas  
- **DuckDB** (analytics engine + semantic layer)  
- **Streamlit** (dashboard)  
- **Plotly** (charts)  
- **RapidFuzz** (fuzzy matching for G1)  

---

## ğŸ“ Repository Structure

```text
DELIVERY-MARKET-ANALYSIS/
â”œâ”€â”€ .venv/
â”œâ”€â”€ .vscode/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ Home.py
â”‚   â””â”€â”€ pages/
â”‚       â”œâ”€â”€ 2_Pricing.py
â”‚       â”œâ”€â”€ 3_Locations.py
â”‚       â”œâ”€â”€ 4_Value.py
â”‚       â”œâ”€â”€ 5_Geo.py
â”‚       â”œâ”€â”€ 6_VegVegan.py
â”‚       â”œâ”€â”€ 7_CrossPlatform.py
â”‚       â”œâ”€â”€ 8_Outliers.py
â”‚       â”œâ”€â”€ 9_Chains.py
â”‚       â””â”€â”€ 10_LateNight.py
â”œâ”€â”€ assets/
â”‚   â””â”€â”€ screenshots/
â”œâ”€â”€ data/
â”œâ”€â”€ sql/
â”‚   â””â”€â”€ 90_views_semantic.sql
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ apply_sql.py
â”‚   â”œâ”€â”€ build_duckdb.py
â”‚   â””â”€â”€ delivery_market_analysis/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ matching.py
â”‚       â””â”€â”€ queries.py
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_ingest_views.py
â”‚   â””â”€â”€ test_smoke.py
â”œâ”€â”€ Makefile
â”œâ”€â”€ pyproject.toml
â””â”€â”€ README.md
```

---

## â–¶ï¸ How to Run Locally

### Prerequisites

- Python 3.11+  
- Virtual environment  

### Installation

```bash
pip install -e ".[dev]"
```

### Build analytics database (SQLite â†’ DuckDB)

```bash
python src/build_duckdb.py --dir data/raw
python src/apply_sql.py
```

### Build G1 matching (cross-platform entity resolution)

```bash
python -m delivery_market_analysis.matching
```

### Run dashboard

```bash
streamlit run app/Home.py
```

---

## ğŸ“Š Dashboard Pages (For Reviewers)

- **Home:** dataset overview and sanity checks  
- **Pricing:** menu item price distribution (clean prices)  
- **Locations:** restaurant distribution per city + map  
- **Geo dish map:** kapsalon (or keyword) locations + average price  
- **Value:** best price-to-rating proxy + top pizza restaurants  
- **Veg/Vegan:** availability by area (text heuristic)  
- **WHO (Hummus):** top hummus restaurants  
- **Cross-platform (G1):** overlap distribution + pairwise overlap + top candidates + hotspots  
- **Outliers:** extreme menu item prices per platform (z-score)  
- **Chains:** chain vs independent proxy  
- **Late night:** UberEats open-late analysis based on hours encoding  

---

## ğŸ“Œ Method Notes (For Coaches / Judges)

### Semantic Layer

- Raw tables remain platform-scoped in DuckDB schemas  
- `stg_*` views standardize types and fields across platforms  
- Convenience views keep queries readable and reusable across the dashboard  

### Data Quality Rules

- **Prices:** invalid values are filtered (`NULL` / `<= 0`), extreme values handled for visualization  
- **Location:** not all sources provide identical location fields (e.g., Deliveroo restaurants have no city)  
- **Hours:** UberEats `end_time` is stored as minutes since midnight and converted to `TIME`  

### G1 Entity Resolution (Cross-platform Matching)

**Approach:**

- Normalize restaurant names (lowercase, punctuation removal, stopwords)  
- Block candidates by normalized city to reduce false positives  
- Fuzzy match (token-set ratio)  
- Union-Find clustering to produce canonical restaurant IDs  

**Outputs:**

- `g1_restaurant_matches`  
- `vw_canonical_restaurants`  

---

## âš ï¸ Limitations

- Text-based dish/veg detection is heuristic and may undercount some items  
- Entity resolution is probabilistic; blocking and thresholds reduce false positives  
- Cross-platform comparisons depend on available fields (fees/hours are not uniform across sources)  

---

## âœ… Evaluation Checklist

### Coverage

- Must-have questions: implemented in dashboard pages (Pricing, Locations, Value, Geo dish map)  
- Open-ended questions: value proxy, dead zones proxy, veg/vegan, WHO hummus, and original questions via Outliers / Chains / Late Night  
- Nice-to-have: semantic layer for readable/optimized SQL, cross-platform overlap via G1  

---

## ğŸŒŸ STAR (Presentation Summary)

### Situation

Three delivery datasets with different schemas and uneven data quality.

### Task

Produce actionable insights and present them clearly, including cross-platform comparisons.

### Action

Built a DuckDB semantic layer, implemented cross-platform restaurant matching (G1), and shipped a Streamlit dashboard including geospatial and pricing insights.

### Result

A reproducible analytics workflow and a story-driven dashboard answering the required business questions and advanced insights.

---

## ğŸ‘¤ Author

Pierrick Van Hoecke â€” BeCode Data Science & AI Bootcamp

